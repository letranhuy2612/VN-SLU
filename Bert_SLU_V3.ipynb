{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tpqlqXOGnCLU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "import utils\n",
        "from trainer import Trainer, TrainerV2\n",
        "from model import BertSLU, BertSLUV2, BertSLUV3\n",
        "from functools import partial\n",
        "from dataset import BertDataset\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eN73cW1enEKT"
      },
      "outputs": [],
      "source": [
        "def custom_collate(tokenizer, is_train, batch):\n",
        "    inputs = tokenizer([i[\"text\"] for i in batch], return_tensors=\"pt\", padding=\"longest\")\n",
        "    if not is_train:\n",
        "        return inputs, torch.zeros_like(inputs[\"input_ids\"]), torch.zeros(inputs[\"input_ids\"].size(0))\n",
        "    seq_len = inputs[\"input_ids\"].size(1)\n",
        "    token_labels = torch.stack([\n",
        "        torch.tensor(i[\"token_label\"] + [-100]*(seq_len - len(i[\"token_label\"]))) for i in batch\n",
        "    ])\n",
        "    intent_labels = torch.tensor([i[\"intent_label\"] for i in batch])\n",
        "    return inputs, token_labels, intent_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6mVloO5enEMw"
      },
      "outputs": [],
      "source": [
        "def get_loader(annotation_path, token_label_path, batch_size=2, test_size=0.3):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
        "    all_data = utils.load_json(token_label_path)\n",
        "    all_data = [v for k, v in all_data.items()]\n",
        "    all_text = [i[\"sentence\"] for i in all_data]\n",
        "    dataset = BertDataset(all_text, all_data)\n",
        "    N = len(dataset)\n",
        "    print(\"Len dataset\", N)\n",
        "    train_size = int(N * (1-test_size))\n",
        "    train_set, valid_set = torch.utils.data.random_split(dataset, [train_size, N-train_size])\n",
        "    if test_size == 0:\n",
        "        train_set = dataset\n",
        "        valid_set = dataset\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=partial(custom_collate, tokenizer, True)\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_set,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=partial(custom_collate, tokenizer, True)\n",
        "    )\n",
        "    return train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a7nbfvJU63f5"
      },
      "outputs": [],
      "source": [
        "def get_test_loader(test_path, batch_size=2):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
        "    sequences = utils.load_json(test_path)\n",
        "    id_seqs = [k for k, v in sequences.items()]\n",
        "    seqs = [v for k, v in sequences.items()]\n",
        "    dataset = BertDataset(seqs)\n",
        "    test_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=partial(custom_collate, tokenizer, False)\n",
        "    )\n",
        "    return test_loader, id_seqs, seqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ4DbGdjnEPR",
        "outputId": "92bcd93d-ffcd-4fd2-fe52-c74364070f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Len dataset 7490\n",
            "Len train_loader: 164 - Len valid_loader: 71\n"
          ]
        }
      ],
      "source": [
        "train_loader, valid_loader = get_loader(\"dataset/train_20230909.jsonl\", \"dataset/train_token_labels_20230909.json\", 32)\n",
        "print(f\"Len train_loader: {len(train_loader)} - Len valid_loader: {len(valid_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbAISnQTBqEW",
        "outputId": "fefa94e4-8f22-4cb2-a376-5edc30c46556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loader, test_file_id, all_seqs = get_test_loader(\"dataset/4gram_test_sentences_v3_32w.json\", 32)\n",
        "len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BkhQPD6IXqd6"
      },
      "outputs": [],
      "source": [
        "!mkdir ./checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PfOxuR5nnEHy"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    epochs = 15\n",
        "    checkpoint_path_it = \"checkpoint/slu_intent.pt\"\n",
        "    checkpoint_path_tk = \"checkpoint/slu_token.pt\"\n",
        "    learning_rate = 1e-5\n",
        "    adam_eps = 1e-8\n",
        "    warmup_steps = 1000\n",
        "    weight_decay = 0.005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrz_jhkRnERs",
        "outputId": "8add59a0-fcbb-42e5-fd19-ad2a24f29d2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of param: 157673999\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "intent_model = BertSLUV3(\"intent_class\", 15, 9, \"vinai/phobert-base-v2\")\n",
        "print(f\"Num of param:\", sum(p.numel() for p in intent_model.parameters()))\n",
        "optimizer = torch.optim.AdamW(intent_model.parameters(), lr=config.learning_rate, eps=config.adam_eps, weight_decay=config.weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-knZKV8BnEUE",
        "outputId": "65b92ccc-0dce-4a3b-f0e8-c915bed199a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: NVIDIA GeForce GTX 1060 6GB\n",
            "Total update step: 2460\n",
            "Epoch: 1\n",
            "Train step: 164 / 164 - loss: 0.18621 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.00343 - acc: 1.0000\n",
            "\t => Train loss: 1.02490 - Train acc: 0.70\n",
            "\t => Valid loss: 0.13297 - Valid acc: 0.96\n",
            "\t => Time: 0:00:56/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 2\n",
            "Train step: 164 / 164 - loss: 0.05465 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00017 - acc: 1.0000\n",
            "\t => Train loss: 0.07252 - Train acc: 0.98\n",
            "\t => Valid loss: 0.04296 - Valid acc: 0.99\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 3\n",
            "Train step: 164 / 164 - loss: 0.00120 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00009 - acc: 1.0000\n",
            "\t => Train loss: 0.02047 - Train acc: 0.99\n",
            "\t => Valid loss: 0.02822 - Valid acc: 0.99\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 4\n",
            "Train step: 164 / 164 - loss: 0.00201 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00008 - acc: 1.0000\n",
            "\t => Train loss: 0.01351 - Train acc: 1.00\n",
            "\t => Valid loss: 0.02009 - Valid acc: 1.00\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 5\n",
            "Train step: 164 / 164 - loss: 0.00103 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00006 - acc: 1.0000\n",
            "\t => Train loss: 0.00798 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03278 - Valid acc: 1.00\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 6\n",
            "Train step: 164 / 164 - loss: 0.00029 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00001 - acc: 1.0000\n",
            "\t => Train loss: 0.00484 - Train acc: 1.00\n",
            "\t => Valid loss: 0.02269 - Valid acc: 1.00\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 7\n",
            "Train step: 164 / 164 - loss: 0.00014 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00001 - acc: 1.0000\n",
            "\t => Train loss: 0.00155 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03581 - Valid acc: 0.99\n",
            "\t => Time: 0:00:54/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 8\n",
            "Train step: 164 / 164 - loss: 0.26583 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.00001 - acc: 1.0000\n",
            "\t => Train loss: 0.00189 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03321 - Valid acc: 1.00\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 9\n",
            "Train step: 164 / 164 - loss: 0.00044 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00001 - acc: 1.0000\n",
            "\t => Train loss: 0.00296 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03044 - Valid acc: 1.00\n",
            "\t => Time: 0:00:54/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 10\n",
            "Train step: 164 / 164 - loss: 0.00007 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00000 - acc: 1.0000\n",
            "\t => Train loss: 0.00012 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03203 - Valid acc: 1.00\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 11\n",
            "Train step: 164 / 164 - loss: 0.00007 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00000 - acc: 1.0000\n",
            "\t => Train loss: 0.00011 - Train acc: 1.00\n",
            "\t => Valid loss: 0.04084 - Valid acc: 0.99\n",
            "\t => Time: 0:00:54/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 12\n",
            "Train step: 164 / 164 - loss: 0.00010 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00000 - acc: 1.0000\n",
            "\t => Train loss: 0.00008 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03307 - Valid acc: 1.00\n",
            "\t => Time: 0:00:56/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 13\n",
            "Train step: 164 / 164 - loss: 0.00006 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00000 - acc: 1.0000\n",
            "\t => Train loss: 0.00006 - Train acc: 1.00\n",
            "\t => Valid loss: 0.04078 - Valid acc: 1.00\n",
            "\t => Time: 0:00:57/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 14\n",
            "Train step: 164 / 164 - loss: 0.00004 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00000 - acc: 1.0000\n",
            "\t => Train loss: 0.00005 - Train acc: 1.00\n",
            "\t => Valid loss: 0.03798 - Valid acc: 1.00\n",
            "\t => Time: 0:00:54/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 15\n",
            "Train step: 164 / 164 - loss: 0.00002 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00000 - acc: 1.0000\n",
            "\t => Train loss: 0.00014 - Train acc: 1.00\n",
            "\t => Valid loss: 0.06043 - Valid acc: 0.99\n",
            "\t => Time: 0:00:53/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n"
          ]
        }
      ],
      "source": [
        "trainer = TrainerV2(intent_model, optimizer, criterion, amp=False, device=device)\n",
        "# trainer.load_checkpoint(\"checkpoint/slu_intent.pt\")\n",
        "trainer.fit(train_loader, valid_loader, epochs=config.epochs, checkpoint=config.checkpoint_path_it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g3exhAyHt81",
        "outputId": "e661a953-e5ee-4811-ed0d-6cd293ffd96f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of param: 135005193\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "token_model = BertSLUV3(\"token_class\", 15, 9, \"vinai/phobert-base-v2\")\n",
        "print(f\"Num of param:\", sum(p.numel() for p in token_model.parameters()))\n",
        "optimizer = torch.optim.AdamW(token_model.parameters(), lr=config.learning_rate, eps=config.adam_eps, weight_decay=config.weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Mjmhu2mAHxKV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on: NVIDIA GeForce GTX 1060 6GB\n",
            "Total update step: 2460\n",
            "Epoch: 1\n",
            "Train step: 164 / 164 - loss: 0.19723 - acc: 0.8519\n",
            "Valid step: 71 / 71 - loss: 0.09072 - acc: 1.0000\n",
            "\t => Train loss: 0.60971 - Train acc: 0.50\n",
            "\t => Valid loss: 0.16559 - Valid acc: 0.86\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 2\n",
            "Train step: 164 / 164 - loss: 0.11214 - acc: 0.8889\n",
            "Valid step: 71 / 71 - loss: 0.05897 - acc: 1.0000\n",
            "\t => Train loss: 0.14670 - Train acc: 0.89\n",
            "\t => Valid loss: 0.09247 - Valid acc: 0.93\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 3\n",
            "Train step: 164 / 164 - loss: 0.06583 - acc: 0.9259\n",
            "Valid step: 71 / 71 - loss: 0.04328 - acc: 1.0000\n",
            "\t => Train loss: 0.09183 - Train acc: 0.92\n",
            "\t => Valid loss: 0.06759 - Valid acc: 0.93\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 4\n",
            "Train step: 164 / 164 - loss: 0.06262 - acc: 0.8889\n",
            "Valid step: 71 / 71 - loss: 0.03342 - acc: 1.0000\n",
            "\t => Train loss: 0.06955 - Train acc: 0.94\n",
            "\t => Valid loss: 0.05590 - Valid acc: 0.94\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 5\n",
            "Train step: 164 / 164 - loss: 0.04699 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.02657 - acc: 1.0000\n",
            "\t => Train loss: 0.05653 - Train acc: 0.94\n",
            "\t => Valid loss: 0.04788 - Valid acc: 0.94\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 6\n",
            "Train step: 164 / 164 - loss: 0.03990 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.02142 - acc: 1.0000\n",
            "\t => Train loss: 0.04671 - Train acc: 0.94\n",
            "\t => Valid loss: 0.04290 - Valid acc: 0.96\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 7\n",
            "Train step: 164 / 164 - loss: 0.03339 - acc: 0.9259\n",
            "Valid step: 71 / 71 - loss: 0.01760 - acc: 1.0000\n",
            "\t => Train loss: 0.03992 - Train acc: 0.95\n",
            "\t => Valid loss: 0.03695 - Valid acc: 0.96\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 8\n",
            "Train step: 164 / 164 - loss: 0.02337 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.01496 - acc: 1.0000\n",
            "\t => Train loss: 0.03462 - Train acc: 0.96\n",
            "\t => Valid loss: 0.03115 - Valid acc: 0.97\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 9\n",
            "Train step: 164 / 164 - loss: 0.01882 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.01264 - acc: 1.0000\n",
            "\t => Train loss: 0.02888 - Train acc: 0.97\n",
            "\t => Valid loss: 0.02758 - Valid acc: 0.98\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 10\n",
            "Train step: 164 / 164 - loss: 0.01851 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.01058 - acc: 1.0000\n",
            "\t => Train loss: 0.02513 - Train acc: 0.98\n",
            "\t => Valid loss: 0.02674 - Valid acc: 0.97\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 11\n",
            "Train step: 164 / 164 - loss: 0.01710 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.00904 - acc: 1.0000\n",
            "\t => Train loss: 0.02155 - Train acc: 0.98\n",
            "\t => Valid loss: 0.02740 - Valid acc: 0.98\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 12\n",
            "Train step: 164 / 164 - loss: 0.01117 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00788 - acc: 1.0000\n",
            "\t => Train loss: 0.01994 - Train acc: 0.98\n",
            "\t => Valid loss: 0.02316 - Valid acc: 0.99\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 13\n",
            "Train step: 164 / 164 - loss: 0.10255 - acc: 0.9630\n",
            "Valid step: 71 / 71 - loss: 0.00686 - acc: 1.0000\n",
            "\t => Train loss: 0.01700 - Train acc: 0.99\n",
            "\t => Valid loss: 0.01988 - Valid acc: 0.98\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 14\n",
            "Train step: 164 / 164 - loss: 0.01346 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00613 - acc: 1.0000\n",
            "\t => Train loss: 0.01581 - Train acc: 0.99\n",
            "\t => Valid loss: 0.01839 - Valid acc: 0.99\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n",
            "Epoch: 15\n",
            "Train step: 164 / 164 - loss: 0.00864 - acc: 1.0000\n",
            "Valid step: 71 / 71 - loss: 0.00523 - acc: 1.0000\n",
            "\t => Train loss: 0.01347 - Train acc: 0.99\n",
            "\t => Valid loss: 0.01979 - Valid acc: 0.99\n",
            "\t => Time: 0:00:48/step - lr: : 1.000000e-05\n",
            "[+] Save checkpoint successfully\n"
          ]
        }
      ],
      "source": [
        "trainer = TrainerV2(token_model, optimizer, criterion, amp=False, device=device)\n",
        "trainer.fit(train_loader, valid_loader, epochs=config.epochs, checkpoint=config.checkpoint_path_tk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnTktstI_m5"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_N-3adxegs7n"
      },
      "outputs": [],
      "source": [
        "!cp -r ./drive/MyDrive/checkpoint/slu_token.pt ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b70jBd_zKrNr",
        "outputId": "d24d6e42-9a87-4d8a-d40c-c2c6ee8d7f2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Model load successful\n",
            "[+] Model load successful\n"
          ]
        }
      ],
      "source": [
        "intent_model = BertSLUV3(\"intent_class\", 15, 9, \"vinai/phobert-base-v2\")\n",
        "token_model = BertSLUV3(\"token_class\", 15, 9, \"vinai/phobert-base-v2\")\n",
        "intent_trainer = TrainerV2(intent_model, optimizer, criterion, amp=False, device=device)\n",
        "intent_trainer.load_checkpoint(\"checkpoint/slu_intent.pt\")\n",
        "token_trainer = TrainerV2(token_model, optimizer, criterion, amp=False, device=device)\n",
        "token_trainer.load_checkpoint(\"checkpoint/slu_token.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEhRLDy7Cnhi",
        "outputId": "d48807a9-7fdc-46f9-9e94-f1708a19bf9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 41 / 41\n",
            " 41 / 41\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1299, 1299)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# trainer = TrainerV2(model, optimizer, criterion, amp=False, device=device)\n",
        "# intent_trainer.load_checkpoint(\"./checkpoint/checkpoint_bert.pt\")\n",
        "_ , all_intents = intent_trainer.test(test_loader)\n",
        "all_tokens, _ = token_trainer.test(test_loader)\n",
        "len(all_tokens), len(all_intents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW5JCiDBFWsA",
        "outputId": "a8d6fb3f-bdf7-48c3-9337-21e5dc43548d"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeZ-AWWzNgF9",
        "outputId": "7626a07d-f926-49c2-ea87-3684e5338465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[6, 0, 14, 3, 1]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_intents[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "92ZSv_lXJR0l"
      },
      "outputs": [],
      "source": [
        "INVERSE_MAP_TOKENS = {\n",
        "    0: 'word',\n",
        "    1: 'time at',\n",
        "    2: 'device',\n",
        "    3: 'changing value',\n",
        "    4: 'scene',\n",
        "    5: 'command',\n",
        "    6: 'location',\n",
        "    7: 'duration',\n",
        "    8: 'target number'\n",
        " }\n",
        "\n",
        "INVERSE_MAP_INTENTS = {\n",
        "    0: 'Giảm độ sáng của thiết bị',\n",
        "    1: 'Đóng thiết bị',\n",
        "    2: 'Hủy hoạt cảnh',\n",
        "    3: 'Tắt thiết bị',\n",
        "    4: 'Tăng âm lượng của thiết bị',\n",
        "    5: 'Giảm mức độ của thiết bị',\n",
        "    6: 'Bật thiết bị',\n",
        "    7: 'Tăng mức độ của thiết bị',\n",
        "    8: 'Tăng nhiệt độ của thiết bị',\n",
        "    9: 'Kiểm tra tình trạng thiết bị',\n",
        "    10: 'Mở thiết bị',\n",
        "    11: 'Giảm âm lượng của thiết bị',\n",
        "    12: 'Kích hoạt cảnh',\n",
        "    13: 'Giảm nhiệt độ của thiết bị',\n",
        "    14: 'Tăng độ sáng của thiết bị'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p-QhP_ztFwzn"
      },
      "outputs": [],
      "source": [
        "def collect_label(token):\n",
        "    token = token[1:]\n",
        "    for i in range(len(token) - 1, -1, -1):\n",
        "        if token[i] != 0:\n",
        "            token = token[:i+1]\n",
        "            break\n",
        "    token += [-1]\n",
        "    map_labels = []\n",
        "    cur = 0\n",
        "    val = token[0]\n",
        "    for idx, i in enumerate(token[1:], 1):\n",
        "        if i == val:\n",
        "            continue\n",
        "        else:\n",
        "            if val != 0:\n",
        "                map_labels.append([cur, idx-1, val])\n",
        "            val = i\n",
        "            cur = idx\n",
        "    return map_labels\n",
        "\n",
        "def convert_into_output(all_tokens, all_intents, all_seqs, test_file_id, tokenizer):\n",
        "    ans = []\n",
        "    for idx in range(len(all_tokens)):\n",
        "        token = all_tokens[idx]\n",
        "        intent = all_intents[idx]\n",
        "        seq = tokenizer.tokenize(all_seqs[idx])\n",
        "        labels = collect_label(token)\n",
        "        tmp_ans = {\n",
        "            \"intent\": INVERSE_MAP_INTENTS[intent],\n",
        "            \"text\": all_seqs[idx]\n",
        "        }\n",
        "        entities = []\n",
        "        # print(labels)\n",
        "        # print(seq)\n",
        "        # return\n",
        "        for label in labels:\n",
        "            if label[-1] == 0:\n",
        "                continue\n",
        "            sub_text = seq[label[0]: label[1]+1]\n",
        "            sub_text = tokenizer.decode(\n",
        "                tokenizer.convert_tokens_to_ids(sub_text), skip_special_tokens=True\n",
        "            )\n",
        "            tmp_add = {\"type\": INVERSE_MAP_TOKENS[label[-1]], \"filler\": sub_text}\n",
        "            # check = list(filter(lambda x: tmp_add[\"type\"] == x[\"type\"] and tmp_add[\"filler\"] == x[\"filler\"], entities))\n",
        "            # if len(check):\n",
        "                # continue\n",
        "            entities += [tmp_add]\n",
        "        tmp_ans[\"entities\"] = entities\n",
        "        ans.append(tmp_ans)\n",
        "        print(\"\\r\", end=\"\")\n",
        "        print(f\"\\r {idx+1} / {len(all_tokens)}\", end=\"\")\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_into_output(all_tokens, all_intents, all_seqs, test_file_id, tokenizer):\n",
        "    ans = []\n",
        "    for idx in range(len(all_tokens)):\n",
        "        token = all_tokens[idx]\n",
        "        intent = all_intents[idx]\n",
        "        seq = tokenizer.tokenize(all_seqs[idx])\n",
        "        labels = collect_label(token)\n",
        "        tmp_ans = {\n",
        "            \"intent\": INVERSE_MAP_INTENTS[intent],\n",
        "            \"text\": all_seqs[idx]\n",
        "        }\n",
        "        entities = []\n",
        "        # print(labels)\n",
        "        # print(seq)\n",
        "        # return\n",
        "        for label in labels:\n",
        "            if label[-1] == 0:\n",
        "                continue\n",
        "            sub_text = seq[label[0]: label[1]+1]\n",
        "            sub_text = tokenizer.decode(\n",
        "                tokenizer.convert_tokens_to_ids(sub_text), skip_special_tokens=True\n",
        "            )\n",
        "            tmp_add = {\"type\": INVERSE_MAP_TOKENS[label[-1]], \"filler\": sub_text}\n",
        "            # check = list(filter(lambda x: tmp_add[\"type\"] == x[\"type\"] and tmp_add[\"filler\"] == x[\"filler\"], entities))\n",
        "            # if len(check):\n",
        "                # continue\n",
        "            entities += [tmp_add]\n",
        "        tmp_ans[\"entities\"] = entities\n",
        "        ans.append(tmp_ans)\n",
        "        print(\"\\r\", end=\"\")\n",
        "        print(f\"\\r {idx+1} / {len(all_tokens)}\", end=\"\")\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_COeQeYzINjD",
        "outputId": "c0148d44-580b-4390-bdc1-94581709c181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1299 / 1299"
          ]
        }
      ],
      "source": [
        "ans = convert_into_output(all_tokens, all_intents, all_seqs, test_file_id, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fBarcgXLXnr",
        "outputId": "3179acdd-cb40-46a1-a747-b55d282914af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'intent': 'Bật thiết bị',\n",
              "  'text': 'bật lúc 9 giờ 40 phút nhá',\n",
              "  'entities': [{'type': 'command', 'filler': 'bật'},\n",
              "   {'type': 'time at', 'filler': '9 giờ 40 phút'}]},\n",
              " {'intent': 'Giảm độ sáng của thiết bị',\n",
              "  'text': 'giảm 33% em ạ',\n",
              "  'entities': [{'type': 'command', 'filler': 'giảm'},\n",
              "   {'type': 'changing value', 'filler': '33%'}]},\n",
              " {'intent': 'Tăng độ sáng của thiết bị',\n",
              "  'text': 'tăng 88% nhé',\n",
              "  'entities': [{'type': 'command', 'filler': 'tăng'},\n",
              "   {'type': 'target number', 'filler': '88%'}]},\n",
              " {'intent': 'Tắt thiết bị',\n",
              "  'text': 'tắt hộ mình cái bóng sân nhá',\n",
              "  'entities': [{'type': 'command', 'filler': 'tắt'},\n",
              "   {'type': 'device', 'filler': 'bóng sân'}]},\n",
              " {'intent': 'Đóng thiết bị',\n",
              "  'text': 'em ơi giúp anh đóng cái lò nướng nhé',\n",
              "  'entities': [{'type': 'command', 'filler': 'đóng'},\n",
              "   {'type': 'device', 'filler': 'lò nướng'}]}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HvN-RjVNL_T7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"predictions.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in ans:\n",
        "        json.dump(line, f,ensure_ascii=False)\n",
        "        f.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovg7oluZPyD-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
