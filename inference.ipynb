{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lehuy\\miniconda3\\envs\\SLU\\lib\\site-packages\\torch\\cuda\\__init__.py:651: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import utils\n",
    "from trainer import Trainer, TrainerV2\n",
    "from model import BertSLU, BertSLUV2, BertSLUV3\n",
    "from functools import partial\n",
    "from dataset import BertDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_model = BertSLUV3(\"intent_class\", 15, 9, \"vinai/phobert-base-v2\")\n",
    "token_model = BertSLUV3(\"token_class\", 15, 9, \"vinai/phobert-base-v2\")\n",
    "params = torch.load('checkpoint/slu_intent.pt',map_location='cpu')\n",
    "intent_model.load_state_dict(params[\"model\"])\n",
    "params = torch.load('checkpoint/slu_token.pt',map_location='cpu')\n",
    "token_model.load_state_dict(params[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"bật đèn bàn xiaomi ở phòng khách \"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "intent_model.eval()\n",
    "token_model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
    "inputs = {k: v.to('cpu') for k, v in inputs.items()}\n",
    "intent_logits = intent_model(inputs)\n",
    "intent_logits = intent_logits[1].argmax(-1).view(-1).tolist() if intent_logits is not None else [None]\n",
    "token_logits = token_model(inputs)\n",
    "token_logits = token_logits[0].argmax(-1).tolist() if token_logits is not None else [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSE_MAP_TOKENS = {\n",
    "    0: 'word',\n",
    "    1: 'time at',\n",
    "    2: 'device',\n",
    "    3: 'changing value',\n",
    "    4: 'scene',\n",
    "    5: 'command',\n",
    "    6: 'location',\n",
    "    7: 'duration',\n",
    "    8: 'target number'\n",
    " }\n",
    "\n",
    "INVERSE_MAP_INTENTS = {\n",
    "    0: 'Giảm độ sáng của thiết bị',\n",
    "    1: 'Đóng thiết bị',\n",
    "    2: 'Hủy hoạt cảnh',\n",
    "    3: 'Tắt thiết bị',\n",
    "    4: 'Tăng âm lượng của thiết bị',\n",
    "    5: 'Giảm mức độ của thiết bị',\n",
    "    6: 'Bật thiết bị',\n",
    "    7: 'Tăng mức độ của thiết bị',\n",
    "    8: 'Tăng nhiệt độ của thiết bị',\n",
    "    9: 'Kiểm tra tình trạng thiết bị',\n",
    "    10: 'Mở thiết bị',\n",
    "    11: 'Giảm âm lượng của thiết bị',\n",
    "    12: 'Kích hoạt cảnh',\n",
    "    13: 'Giảm nhiệt độ của thiết bị',\n",
    "    14: 'Tăng độ sáng của thiết bị'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bật thiết bị'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INVERSE_MAP_INTENTS[intent_logits[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_label(token):\n",
    "    token = token[1:]\n",
    "    for i in range(len(token) - 1, -1, -1):\n",
    "        if token[i] != 0:\n",
    "            token = token[:i+1]\n",
    "            break\n",
    "    token += [-1]\n",
    "    map_labels = []\n",
    "    cur = 0\n",
    "    val = token[0]\n",
    "    for idx, i in enumerate(token[1:], 1):\n",
    "        if i == val:\n",
    "            continue\n",
    "        else:\n",
    "            if val != 0:\n",
    "                map_labels.append([cur, idx-1, val])\n",
    "            val = i\n",
    "            cur = idx\n",
    "    return map_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTENTS: Bật thiết bị\n",
      "ENTITIES: [{'type': 'command', 'filler': 'bật'}, {'type': 'device', 'filler': 'đèn bàn xiami'}, {'type': 'location', 'filler': 'phòng khách'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"INTENTS:\",INVERSE_MAP_INTENTS[intent_logits[0]])\n",
    "token = token_logits[0]\n",
    "seq = tokenizer.tokenize(sentence)\n",
    "labels = collect_label(token)\n",
    "entities = []\n",
    "for label in labels:\n",
    "    if label[-1] == 0:\n",
    "        continue\n",
    "    sub_text = seq[label[0]: label[1]+1]\n",
    "    sub_text = tokenizer.decode(\n",
    "        tokenizer.convert_tokens_to_ids(sub_text), skip_special_tokens=True\n",
    "    )\n",
    "    tmp_add = {\"type\": INVERSE_MAP_TOKENS[label[-1]], \"filler\": sub_text}\n",
    "    entities += [tmp_add]\n",
    "print(\"ENTITIES:\",entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
